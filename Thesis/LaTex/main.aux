\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@input{Exercises/Introduction/Abstract.aux}
\@input{Exercises/Introduction/Introduction.aux}
\@input{Exercises/Theory/Theory.aux}
\citation{gradientdescent}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}F1-score}{6}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Optimization}{6}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Gradient descent}{6}{subsubsection.3.4.1}\protected@file@percent }
\citation{GD1DIllustration}
\citation{GD2DIllustration}
\citation{GD1DIllustration}
\citation{GD2DIllustration}
\citation{adam}
\citation{dropout}
\citation{dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Examples of gradient descent. Illustrations taken from \cite  {GD1DIllustration}\cite  {GD2DIllustration}.\relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{gdIllustrations}{{4}{7}{Examples of gradient descent. Illustrations taken from \cite {GD1DIllustration}\cite {GD2DIllustration}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Adam}{7}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Regularization}{7}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Dropout}{7}{subsubsection.3.5.1}\protected@file@percent }
\citation{weightdecay}
\citation{normalization}
\citation{errorsurface}
\citation{batchnormalization}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Weight decay}{8}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Normalization}{8}{subsubsection.3.5.3}\protected@file@percent }
\newlabel{normalizationexamplea}{{5a}{8}{Non standardized data\relax }{figure.caption.5}{}}
\newlabel{sub@normalizationexamplea}{{a}{8}{Non standardized data\relax }{figure.caption.5}{}}
\newlabel{normalizationexampleb}{{5b}{8}{Standardized data\relax }{figure.caption.5}{}}
\newlabel{sub@normalizationexampleb}{{b}{8}{Standardized data\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Examples of gradient descent optimization on non-standardized data and on standardized data. The blue line is the gradient steps taken during optimization. If the data is not standardized, the error surface becomes elongated, and the gradient steps points away from the minima, resulting in the gradient steps becoming 'zig-zaggy' and inefficient. If the data is standardized, the error surface becomes less elongated, and the gradient steps points more directly towards the minima, resulting in more efficient gradient steps.\relax }}{8}{figure.caption.5}\protected@file@percent }
\citation{batchnormalization}
\citation{errorsurface}
\citation{batchnormalization}
\citation{ROC}
\citation{ROC}
\citation{ROC}
\citation{ROC}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}ROC curve}{9}{subsection.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Examples of how different area under the curve are achieved. Illustrations are from \cite  {ROC}.\relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{ROC}{{6}{10}{Examples of how different area under the curve are achieved. Illustrations are from \cite {ROC}.\relax }{figure.caption.6}{}}
\@input{Exercises/Methods/Methods.aux}
\@input{Exercises/Results/Results.aux}
\@input{Exercises/Discussion/Discussion.aux}
\@input{Exercises/Conclusion/Conclusion.aux}
\bibcite{colitis}{1}
\bibcite{lecun}{2}
\bibcite{CNN}{3}
\bibcite{unet}{4}
\bibcite{resnetPaper}{5}
\bibcite{resnet}{6}
\bibcite{resnetModel}{7}
\bibcite{crossentropy}{8}
\bibcite{gradientdescent}{9}
\bibcite{adam}{10}
\bibcite{GD2DIllustration}{11}
\bibcite{GD1DIllustration}{12}
\bibcite{dropout}{13}
\bibcite{weightdecay}{14}
\bibcite{normalization}{15}
\bibcite{errorsurface}{16}
\bibcite{batchnormalization}{17}
\bibcite{ROC}{18}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{35}{section.8}\protected@file@percent }
\zref@newlabel{LastPage}{\default{7}\page{35}\abspage{37}}
