{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Analysis: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these instructions (https://github.com/antoniosehk/keras-tensorflow-windows-installation) and apply everything that is needed to run tensorflow and keras. Check if your computer has GPU compatible with NVIDIA drivers. If it is not compatible or you do not have GPU, there are two options available:\n",
    "\n",
    "1) Use CPU. Our project is not going to be super computationally expensive\n",
    "\n",
    "2) Use Colab, follow the first lecture and check here https://colab.research.google.com/notebooks/gpu.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a database with chest X-rays with lung segmentaiton. Please use imread from pyplot to read X-rays and lung masks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading gif images as numpy arrays\n",
    "leftLung = imread(\"scratch/fold1/masks/left lung/JPCLN001.gif\")\n",
    "rightLung = imread(\"scratch/fold1/masks/right lung/JPCLN001.gif\")\n",
    "bothLungs = leftLung + rightLung\n",
    "#im2 = imread(\".....bmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1. Read the assignemtn data and separate it into training and testing parts\n",
    "\n",
    "All raw X-ray images are stored at \"Data\\scratch\\images\".\n",
    "The training and testing masks of the database are stored in two folders named \"Data\\scratch\\fold1\\masks\\\" and \"Data\\scratch\\fold2\\masks\\\", repsectively. The organs of interest include \"left lung\" and \"right lung\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate 4 numpy arrays mask_array_training, im_array_training, mask_array_testing, im_array_testing:\n",
    "\n",
    "    0) n_training_cases = len(glob.glob('...Data\\scratch\\fold1\\masks\\left lung\\'))\n",
    "       n_testing_cases = len(glob.glob('...Data\\scratch\\fold2\\masks\\left lung\\'))\n",
    "    \n",
    "    \n",
    "    1) mask_array_training # should be of size (n_training_cases x 256 x 256) generated from images in folders \"Data\\scratch\\fold1\\masks\\left lung\" and \"Data\\scratch\\fold1\\masks\\right lung\".\n",
    "    \n",
    "    2) im_array_training # should be of size (n_training_cases x 256 x 256) generated from images in folder \"Data\\scratch\\images\". To be sure get case name from every file in \"Data\\scratch\\fold1\\masks\\left lung\" and find the matching file in \"Data\\scratch\\images\"\n",
    "    \n",
    "        a) files = glob.glob('...Data\\scratch\\fold1\\masks\\left lung\\')\n",
    "        b) fileName = os.path.basename(files[i])\n",
    "        c) fileNameWithoutExtension = os.path.splitext(fileName)[0]\n",
    "    \n",
    "    3) mask_array_testing # should be of size (n_testing_cases x 256 x 256) generated from images in folder \"Data\\scratch\\fold2\\masks\\left lung\" and \"Data\\scratch\\fold2\\masks\\right lung\".\n",
    "    \n",
    "    4) im_array_testing # should be of size (n_testing_cases x 256 x 256) generated from images in folder \"Data\\scratch\\images\" to match testing masks in \"Data\\scratch\\fold2\\masks\\left lung\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "123\n",
      "(124, 256, 256)\n",
      "(124, 256, 256)\n",
      "(123, 256, 256)\n",
      "(123, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "n_training_cases = len(glob.glob('./scratch/fold1/masks/left lung/*'))\n",
    "n_testing_cases = len(glob.glob('./scratch/fold2/masks/left lung/*'))\n",
    "print(n_training_cases)\n",
    "print(n_testing_cases)\n",
    "\n",
    "# Training masks\n",
    "filesLeft = glob.glob('./scratch/fold1/masks/left lung/*')\n",
    "filesRight = glob.glob('./scratch/fold1/masks/right lung/*')\n",
    "mask_array_training = np.array([cv2.resize(plt.imread(L)+plt.imread(R),(256,256)) for L,R in zip(filesLeft,filesRight)])\n",
    "print(mask_array_training.shape)\n",
    "\n",
    "# Training images\n",
    "files = glob.glob('./scratch/fold1/masks/left lung/*')\n",
    "im_array_training = np.array([cv2.cvtColor(cv2.imread('scratch/images/'+os.path.splitext(os.path.basename(file))[0]+'.bmp'),cv2.COLOR_BGR2GRAY) for file in files])\n",
    "print(im_array_training.shape)\n",
    "\n",
    "# Test masks\n",
    "filesLeft = glob.glob('./scratch/fold2/masks/left lung/*')\n",
    "filesRight = glob.glob('./scratch/fold2/masks/right lung/*')\n",
    "mask_array_testing = np.array([cv2.resize(plt.imread(L)+plt.imread(R),(256,256)) for L,R in zip(filesLeft,filesRight)])\n",
    "print(mask_array_testing.shape)\n",
    "\n",
    "# Test images\n",
    "files = glob.glob('./scratch/fold2/masks/left lung/*')\n",
    "im_array_training = np.array([cv2.cvtColor(cv2.imread('scratch/images/'+os.path.splitext(os.path.basename(file))[0]+'.bmp'),cv2.COLOR_BGR2GRAY) for file in files])\n",
    "print(im_array_training.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2. Adapt some existing implementation of Unet for the segmentation of lung fields. Train the Unet on fold1 of the database.\n",
    "\n",
    "Check this link for Unet implementation https://github.com/zhixuhao/unet\n",
    "\n",
    "Here is the implementation of the Unet https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "Move learning rate (lr) to the parameters of the unet()\n",
    "\n",
    "Here is an example of how to visualize results of network training, you will need them for your report https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "\n",
    "Some implementation hits for training Unets:\n",
    "\n",
    "    0) par_batch_size = 10\n",
    "       par_epochs = 100\n",
    "       par_validation_split = 0.15\n",
    "       par_learning_rate = 0.0001\n",
    "       # play with these parameters to find best combination\n",
    "\n",
    "    1) model = unet(input_size = (256, 256, 1), lr = par_learning_rate) # generate Unet\n",
    "        \n",
    "    2) validationSplit = 0.15\n",
    "       \n",
    "    3) im_array_training = np.expand_dims(np.asarray(im_array_training), axis = 4)\n",
    "       mask_array_training = np.expand_dims(np.asarray(mask_array_training, dtype = np.float), axis = 4)\n",
    "       # this is needed to add an explicit dimension at the end of the training data. You can basically consider this as color of the image. You add one dimension of size one to indicate that there is only one data channel per input example\n",
    "        \n",
    "    4) model.fit(im_array_training, mask_array_training, batch_size = par_batch_size, epochs = par_epochs, validation_split = par_validation_split)\n",
    "    \n",
    "    5) model.save('../resultUnet.hdf5') # save model somewhere on your disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3. Test the Unet performance on fold2. Use Dice coefficient to evaluate the Unet performance.\n",
    "\n",
    "Some implementation hits for testing Unet:\n",
    "    \n",
    "    0) model = load_model('../resultUnet.hdf5') # load model\n",
    "    \n",
    "    1) results = model.predict(np.expand_dims(np.asarray(im_array_testing), axis = 4), batch_size = 5)\n",
    "    \n",
    "    2) results[i, :, :, 0] # this is the result of segmentation corresponding to im_array_testing[i]\n",
    "    \n",
    "    3) compute_dice(results[i, :, :, 0], mask_array_testing[i]) # compute the dice for ith testing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks for the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Train and test Unet for segmentation of lung fields.\n",
    "\n",
    "2) Select appropriate par_batch_size, par_epochs, par_validation_split, par_learning_rate. Explain what these parameters mean and how did you choice\n",
    "   (check this https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)\n",
    "\n",
    "3) Plot loss functions for training and validation\n",
    "\n",
    "4) Plot results for cases JPCLN016, JPCLN048, JPCLN058. Explain why you think the results look like this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
